---
description:
globs:
alwaysApply: true
---
# Anthropic Claude API Documentation

## Table of Contents

1. [Introduction](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#introduction)
2. [Models](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#models)
3. [Getting Started](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#getting-started)
4. [Core Features](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#core-features)
5. [API Reference](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#api-reference)
6. [Pricing](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#pricing)
7. [Additional Resources](https://claude.ai/chat/5b9721f1-8823-4fe3-aff1-1351af758f26#additional-resources)

---

## Introduction

### Overview

Anthropic's Claude API provides access to state-of-the-art large language models designed for safety, helpfulness, and honesty. Claude models excel at complex reasoning, creative writing, code generation, and multimodal tasks.

### Key Features

- **Advanced Reasoning**: Superior performance on complex analytical tasks
- **Extended Context**: Up to 200K tokens (1M in beta for Sonnet 4)
- **Multimodal Capabilities**: Process text, images, and PDFs
- **Tool Use**: Function calling and code execution
- **Safety-First Design**: Built with Constitutional AI principles

---

## Models

### Model Families

#### Claude Opus 4.1

**Most powerful and capable model**

|Feature|Details|
|---|---|
|**Model ID**|`claude-opus-4-1-20250805`|
|**Context Window**|200K tokens|
|**Max Output**|32,000 tokens|
|**Training Cutoff**|March 2025|
|**Strengths**|Highest intelligence, superior reasoning|
|**Best For**|Complex analysis, research, creative tasks|

#### Claude Opus 4

|Feature|Details|
|---|---|
|**Model ID**|`claude-opus-4-20250514`|
|**Context Window**|200K tokens|
|**Max Output**|32,000 tokens|
|**Training Cutoff**|March 2025|
|**Strengths**|Very high intelligence and capability|

#### Claude Sonnet 4

|Feature|Details|
|---|---|
|**Model ID**|`claude-sonnet-4-20250514`|
|**Context Window**|200K (1M beta available)|
|**Max Output**|64,000 tokens|
|**Training Cutoff**|March 2025|
|**Strengths**|Balanced performance and speed|
|**Best For**|High-performance tasks with efficiency|

#### Claude Sonnet 3.7

|Feature|Details|
|---|---|
|**Model ID**|`claude-3-7-sonnet-20250219`|
|**Alias**|`claude-3-7-sonnet-latest`|
|**Context Window**|200K tokens|
|**Max Output**|64,000 tokens (128K with beta)|
|**Training Cutoff**|November 2024|
|**Special Feature**|Extended thinking capability|

#### Claude Haiku 3.5

|Feature|Details|
|---|---|
|**Model ID**|`claude-3-5-haiku-20241022`|
|**Alias**|`claude-3-5-haiku-latest`|
|**Context Window**|200K tokens|
|**Max Output**|8,192 tokens|
|**Training Cutoff**|July 2024|
|**Strengths**|Fastest response times|
|**Best For**|High-throughput, simple tasks|

#### Claude Haiku 3

|Feature|Details|
|---|---|
|**Model ID**|`claude-3-haiku-20240307`|
|**Context Window**|200K tokens|
|**Max Output**|4,096 tokens|
|**Training Cutoff**|August 2023|
|**Strengths**|Quick and compact|

### Platform Availability

|Platform|Model Name Format|Example|
|---|---|---|
|**Anthropic API**|Direct model names|`claude-opus-4-1-20250805`|
|**AWS Bedrock**|With provider prefix|`anthropic.claude-opus-4-1-20250805-v1:0`|
|**GCP Vertex AI**|With @ separator|`claude-opus-4-1@20250805`|

---

## Getting Started

### Prerequisites

1. Create an [Anthropic Console account](https://console.anthropic.com/)
2. Generate an [API key](https://console.anthropic.com/settings/keys)
3. Set up your development environment

### Quick Start

#### Installation

**Python**

bash

```bash
pip install anthropic
```

**TypeScript/JavaScript**

bash

```bash
npm install @anthropic-ai/sdk
```

**Java**

xml

```xml
<dependency>
  <groupId>com.anthropic</groupId>
  <artifactId>anthropic-java</artifactId>
  <version>1.0.0</version>
</dependency>
```

#### Basic Example

python

```python
import anthropic

client = anthropic.Anthropic()

message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1000,
    messages=[
        {
            "role": "user",
            "content": "What are the key principles of effective communication?"
        }
    ]
)

print(message.content)
```

#### With System Prompt

python

```python
message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1000,
    system="You are a helpful assistant specialized in technical documentation.",
    messages=[
        {
            "role": "user",
            "content": "Explain REST API design principles"
        }
    ]
)
```

---

## Core Features

### Messages API

The primary API for interacting with Claude models.

#### Basic Structure

python

```python
response = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    temperature=0.7,
    system="System instructions here",
    messages=[
        {"role": "user", "content": "User message"},
        {"role": "assistant", "content": "Previous assistant response"},
        {"role": "user", "content": "Follow-up question"}
    ]
)
```

#### Streaming Responses

python

```python
with client.messages.stream(
    model="claude-sonnet-4-20250514",
    max_tokens=1000,
    messages=[{"role": "user", "content": "Tell me a story"}]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

### Vision Capabilities

Process and analyze images with Claude 3+ models.

#### Image Input Methods

**Base64 Encoding**

python

```python
import base64

with open("image.jpg", "rb") as f:
    image_data = base64.standard_b64encode(f.read()).decode("utf-8")

message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": image_data
                }
            },
            {
                "type": "text",
                "text": "What's in this image?"
            }
        ]
    }]
)
```

**URL Reference**

python

```python
message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "image",
                "source": {
                    "type": "url",
                    "url": "https://example.com/image.jpg"
                }
            },
            {
                "type": "text",
                "text": "Describe this image"
            }
        ]
    }]
)
```

#### Image Requirements

|Requirement|Specification|
|---|---|
|**Formats**|JPEG, PNG, GIF, WebP|
|**Max Size**|5MB (API), 10MB (claude.ai)|
|**Max Resolution**|8000×8000 pixels|
|**Max Images**|100 per request (API), 20 (claude.ai)|
|**Optimal Size**|1.15 megapixels|

#### Token Calculation

```
tokens = (width_px × height_px) / 750
```

### PDF Support

Process PDF documents with Claude 3.5+ models.

#### PDF Input Methods

**URL-based**

python

```python
message = client.messages.create(
    model="claude-opus-4-1-20250805",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "document",
                "source": {
                    "type": "url",
                    "url": "https://example.com/document.pdf"
                }
            },
            {
                "type": "text",
                "text": "Summarize this document"
            }
        ]
    }]
)
```

**Base64-encoded**

python

```python
import base64

with open("document.pdf", "rb") as f:
    pdf_data = base64.standard_b64encode(f.read()).decode("utf-8")

message = client.messages.create(
    model="claude-opus-4-1-20250805",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "document",
                "source": {
                    "type": "base64",
                    "media_type": "application/pdf",
                    "data": pdf_data
                }
            },
            {
                "type": "text",
                "text": "What are the key findings?"
            }
        ]
    }]
)
```

#### PDF Requirements

|Requirement|Limit|
|---|---|
|**Max Request Size**|32MB|
|**Max Pages**|100 pages|
|**Format**|Standard PDF (no encryption)|
|**Token Usage**|1,500-3,000 per page|

### Files API (Beta)

Upload files once and reference them multiple times.

#### Upload File

python

```python
file_upload = client.beta.files.upload(
    file=("document.pdf", open("document.pdf", "rb"), "application/pdf")
)
```

#### Use File in Message

python

```python
message = client.beta.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    betas=["files-api-2025-04-14"],
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "document",
                "source": {
                    "type": "file",
                    "file_id": file_upload.id
                }
            },
            {
                "type": "text",
                "text": "Analyze this document"
            }
        ]
    }]
)
```

#### File Management

python

```python
# List files
files = client.beta.files.list()

# Get file metadata
file_info = client.beta.files.retrieve_metadata("file_id")

# Delete file
client.beta.files.delete("file_id")

# Download file (only for tool-generated files)
content = client.beta.files.download("file_id")
```

#### Storage Limits

- **Max file size**: 500MB per file
- **Total storage**: 100GB per organization
- **Supported types**: PDF, images, text, datasets

### Tool Use

Enable Claude to call functions and use tools.

#### Basic Function Calling

python

```python
tools = [{
    "name": "get_weather",
    "description": "Get current weather for a location",
    "input_schema": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "City and country"
            },
            "unit": {
                "type": "string",
                "enum": ["celsius", "fahrenheit"]
            }
        },
        "required": ["location"]
    }
}]

message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1000,
    tools=tools,
    messages=[{
        "role": "user",
        "content": "What's the weather in Paris?"
    }]
)
```

#### Processing Tool Calls

python

```python
for content in message.content:
    if content.type == "tool_use":
        tool_name = content.name
        tool_input = content.input
        
        # Execute tool based on name
        if tool_name == "get_weather":
            result = get_weather_function(tool_input)
            
            # Send result back
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1000,
                messages=[
                    {"role": "user", "content": "What's the weather in Paris?"},
                    {"role": "assistant", "content": message.content},
                    {
                        "role": "user",
                        "content": [{
                            "type": "tool_result",
                            "tool_use_id": content.id,
                            "content": str(result)
                        }]
                    }
                ]
            )
```

### Prompt Caching

Reduce costs and latency for repeated content.

python

```python
message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "Long reference document here...",
                "cache_control": {"type": "ephemeral"}
            },
            {
                "type": "text",
                "text": "Question about the document"
            }
        ]
    }]
)
```

#### Cache Duration Options

|Duration|Write Cost|Read Cost|
|---|---|---|
|**5 minutes**|1.25× base|0.1× base|
|**1 hour**|2× base|0.1× base|

### Batch Processing

Process multiple requests asynchronously with 50% discount.

python

```python
batch = client.messages.batches.create(
    requests=[
        {
            "custom_id": "req1",
            "params": {
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 1000,
                "messages": [{"role": "user", "content": "Question 1"}]
            }
        },
        {
            "custom_id": "req2",
            "params": {
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 1000,
                "messages": [{"role": "user", "content": "Question 2"}]
            }
        }
    ]
)

# Check batch status
status = client.messages.batches.retrieve(batch.id)
```

---

## API Reference

### Message Parameters

|Parameter|Type|Description|Default|
|---|---|---|---|
|`model`|string|Model identifier|Required|
|`messages`|array|Conversation messages|Required|
|`max_tokens`|integer|Maximum tokens to generate|Required|
|`system`|string|System instructions|None|
|`temperature`|float|Randomness (0-1)|1.0|
|`top_p`|float|Nucleus sampling|0.999|
|`top_k`|integer|Top-k sampling|None|
|`stop_sequences`|array|Stop generation triggers|None|
|`stream`|boolean|Stream response|false|
|`metadata`|object|Custom metadata|None|

### Response Structure

python

```python
{
    "id": "msg_123",
    "type": "message",
    "role": "assistant",
    "content": [
        {
            "type": "text",
            "text": "Response text here"
        }
    ],
    "model": "claude-sonnet-4-20250514",
    "stop_reason": "end_turn",
    "stop_sequence": null,
    "usage": {
        "input_tokens": 25,
        "output_tokens": 125
    }
}
```

### Error Handling

python

```python
try:
    message = client.messages.create(...)
except anthropic.RateLimitError as e:
    print(f"Rate limit exceeded: {e}")
except anthropic.APIError as e:
    print(f"API error: {e}")
except Exception as e:
    print(f"Unexpected error: {e}")
```

### Rate Limits

|Tier|RPM|TPM|Daily Spend|
|---|---|---|---|
|**Free**|5|20K|$0|
|**Build (Tier 1)**|50|50K|$5|
|**Build (Tier 2)**|1,000|200K|$40|
|**Scale (Tier 3)**|2,000|2M|$200|
|**Scale (Tier 4)**|4,000|10M|$1,000|

---

## Pricing

### Model Pricing (per Million Tokens)

|Model|Input|Cache Write (5m)|Cache Write (1h)|Cache Read|Output|
|---|---|---|---|---|---|
|**Claude Opus 4.1**|$15|$18.75|$30|$1.50|$75|
|**Claude Opus 4**|$15|$18.75|$30|$1.50|$75|
|**Claude Sonnet 4**|$3|$3.75|$6|$0.30|$15|
|**Claude Sonnet 3.7**|$3|$3.75|$6|$0.30|$15|
|**Claude Haiku 3.5**|$0.80|$1|$1.60|$0.08|$4|
|**Claude Haiku 3**|$0.25|$0.30|$0.50|$0.03|$1.25|

### Batch Processing Pricing

50% discount on both input and output tokens:

|Model|Batch Input|Batch Output|
|---|---|---|
|**Claude Opus 4.1**|$7.50/MTok|$37.50/MTok|
|**Claude Sonnet 4**|$1.50/MTok|$7.50/MTok|
|**Claude Haiku 3.5**|$0.40/MTok|$2/MTok|

### Long Context Pricing (Sonnet 4)

For requests exceeding 200K input tokens:

|Token Range|Input|Output|
|---|---|---|
|≤ 200K|$3/MTok|$15/MTok|
|> 200K|$6/MTok|$22.50/MTok|

### Tool Use Pricing

Additional tokens consumed by tool use:

|Model|Tool Choice|System Prompt Tokens|
|---|---|---|
|**Claude Opus 4.1**|auto/none|346 tokens|
|**Claude Opus 4.1**|any/tool|313 tokens|
|**Claude Sonnet 4**|auto/none|346 tokens|
|**Claude Sonnet 4**|any/tool|313 tokens|
|**Claude Haiku 3.5**|auto/none|264 tokens|
|**Claude Haiku 3.5**|any/tool|340 tokens|

---

## Additional Resources

### Best Practices

#### Prompt Engineering

1. **Clear Instructions**: Be specific and detailed
2. **System Prompts**: Use for consistent behavior
3. **Few-shot Examples**: Provide examples for complex tasks
4. **XML Tags**: Structure complex prompts with XML
5. **Chain of Thought**: Ask Claude to think step-by-step

#### Image Best Practices

1. **Image Placement**: Place images before text
2. **Resolution**: Resize to ~1.15 megapixels
3. **Format**: Use JPEG for photos, PNG for diagrams
4. **Multiple Images**: Label as "Image 1:", "Image 2:", etc.

#### Cost Optimization

1. **Use Appropriate Models**: Haiku for simple tasks, Opus for complex
2. **Enable Caching**: For repeated content
3. **Batch Processing**: For non-urgent requests
4. **Optimize Token Usage**: Concise prompts, controlled outputs

### Migration Guide

#### From GPT to Claude

python

```python
# OpenAI
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}]
)

# Anthropic
message = anthropic.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1000,
    messages=[{"role": "user", "content": "Hello"}]
)
```

#### Key Differences

|Feature|OpenAI|Anthropic|
|---|---|---|
|**Max tokens**|Optional|Required|
|**System message**|In messages array|Separate parameter|
|**Streaming**|`stream=True`|`with client.messages.stream()`|
|**Vision**|Separate endpoint|Same Messages API|
|**Tools**|`functions`|`tools`|

### SDK Libraries

|Language|Installation|Repository|
|---|---|---|
|**Python**|`pip install anthropic`|[GitHub](https://github.com/anthropics/anthropic-sdk-python)|
|**TypeScript/JS**|`npm install @anthropic-ai/sdk`|[GitHub](https://github.com/anthropics/anthropic-sdk-typescript)|
|**Java**|Maven/Gradle|[GitHub](https://github.com/anthropics/anthropic-sdk-java)|

### Support & Community

- **Documentation**: [docs.anthropic.com](https://docs.anthropic.com/)
- **Console**: [console.anthropic.com](https://console.anthropic.com/)
- **Support**: [support.anthropic.com](https://support.anthropic.com/)
- **Discord**: [anthropic.com/discord](https://anthropic.com/discord)
- **Cookbook**: [GitHub](https://github.com/anthropics/anthropic-cookbook)

### Compliance & Safety

- **Acceptable Use Policy**: No illegal content, harassment, or deception
- **Data Privacy**: No training on user data
- **Content Filtering**: Automatic safety checks
- **Usage Monitoring**: Track via Console dashboard

---

## Appendix

### Environment Setup

**Set API Key (Bash)**

bash

```bash
export ANTHROPIC_API_KEY='your-api-key-here'
```

**Set API Key (Python)**

python

```python
import os
os.environ['ANTHROPIC_API_KEY'] = 'your-api-key-here'
```

**Set API Key (Node.js)**

javascript

```javascript
process.env.ANTHROPIC_API_KEY = 'your-api-key-here'
```

### Common Error Codes

|Code|Description|Solution|
|---|---|---|
|400|Bad Request|Check parameters|
|401|Authentication Error|Verify API key|
|403|Permission Denied|Check permissions|
|404|Not Found|Verify endpoint/resource|
|429|Rate Limited|Implement backoff|
|500|Server Error|Retry with backoff|
|529|Overloaded|Retry later|

### Token Estimation

- **1 token ≈ 4 characters** (English)
- **1 token ≈ 0.75 words** (English)
- **100 tokens ≈ 75 words**
- **1,000 tokens ≈ 750 words**
- **10,000 tokens ≈ 7,500 words**

재시도